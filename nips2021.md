Associating Objects with Transformers for Video Object Segmentation
COHESIV: Contrastive Object and Hand Embedding Segmentation in Video
Contrastive Learning of Global and Local Video Representation
Relational Self-Attention: What's missing in Attention for Video Understanding
Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Objectt Segmentation
Keeping Your Eye on tha Ball: Trajectory Attention in Video Transformers
TokenLearner: Adaptive Space-Time Tokenization for Videos
The Emergence of Objectness: Learning Zero-shot Segmentation from Videos
Temporal-attentive Covariance Pooling Networks for Video Recognition
CCVS: Context-aware Controllable Video Synthesis
Compressed Video Contrastive Learning
Deep Contextual Video Compression
Space-time Mixing Attention for Video Transformer
SIMONe: View-Invariant, Temporally-Abstracted Object Representations vi Unsupervised Video Decomposition
NeRV: Neural Representation for Videos
Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing
VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text
Dense Unsupervised Learning for Video Segmentation
MAU: A Motion-Aware Unit for Video Prediction and Beyond
Combinatorial Optimization for Panoptic Segmentation: A Fully Differentiable Approach
Semi-Supervised Semantic Segmentation via Adaptive Equalization Learning
